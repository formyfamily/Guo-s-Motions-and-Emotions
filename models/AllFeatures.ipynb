{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, precision_score, recall_score, precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import f_regression, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, fit_grid_point\n",
    "from sklearn import svm\n",
    "from scipy.stats import pearsonr\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_features(dev_features_raw, test_features_raw, annotations, maxk, reg=True, scale=True):\n",
    "    dev_features = preprocessing.minmax_scale(dev_features_raw, feature_range=(0, 1), axis=0) if scale else dev_features_raw\n",
    "    test_features = preprocessing.minmax_scale(test_features_raw, feature_range=(0, 1), axis=0) if scale else test_features_raw\n",
    "    print(dev_features.shape, test_features.shape)\n",
    "    bestk_selection = SelectKBest(f_regression if reg else f_classif, k=maxk)\n",
    "    dev_features_selected = bestk_selection.fit_transform(dev_features, annotations)\n",
    "    test_features_selected = bestk_selection.transform(test_features)\n",
    "    print(dev_features_selected.shape, test_features_selected.shape)\n",
    "    return dev_features_selected, test_features_selected\n",
    "\n",
    "def cat_features(feature1, feature2):\n",
    "    f1_d, f1_t = feature1\n",
    "    f2_d, f2_t = feature2\n",
    "    return (np.concatenate((f1_d, f2_d), 1), np.concatenate((f1_t, f2_t), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_features_vgg = np.load('../data/dev_uploaded_data/vgg_features_avg.npy')\n",
    "dev_features_cls = np.load('../data/dev_uploaded_data/features_avg.npy')\n",
    "dev_annotations = np.load('../data/dev_uploaded_data/anno_valence_arousal.npy')\n",
    "dev_annotations_fear = np.load('../data/dev_uploaded_data/anno_fear.npy')\n",
    "test_features_vgg = np.load('../data/test_uploaded_data/vgg_features_avg.npy')\n",
    "test_features_cls = np.load('../data/test_uploaded_data/features_avg.npy')\n",
    "test_annotations = np.load('../data/test_uploaded_data/anno_valence_arousal.npy')\n",
    "test_annotations_fear = np.load('../data/test_uploaded_data/anno_fear.npy')\n",
    "\n",
    "dev_features_valence, test_features_valence = cat_features(\n",
    "     select_features(dev_features_vgg, test_features_vgg, dev_annotations[:, 0], 100),\n",
    "     select_features(dev_features_cls, test_features_cls, dev_annotations[:, 0], 100))\n",
    "dev_features_arousal, test_features_arousal = cat_features(\n",
    "     select_features(dev_features_vgg, test_features_vgg, dev_annotations[:, 1], 100),\n",
    "     select_features(dev_features_cls, test_features_cls, dev_annotations[:, 1], 100))\n",
    "dev_features_fear, test_features_fear = cat_features(\n",
    "     select_features(dev_features_vgg, test_features_vgg, dev_annotations_fear, 100, False),\n",
    "     select_features(dev_features_cls, test_features_cls, dev_annotations_fear, 100, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_features_valence.shape, test_features_valence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valence model using mixed features to test feature behavior\n",
    "valence_model = GradientBoostingRegressor()\n",
    "valence_model.fit(dev_features_valence, dev_annotations[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_pred = valence_model.predict(test_features_valence)\n",
    "print(mean_squared_error(test_annotations[:,0], valence_pred), pearsonr(test_annotations[:,0], valence_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in range(3, 11, 1):\n",
    "    print('val = {}'.format(val))\n",
    "    valence_model = GradientBoostingRegressor(max_depth=val)\n",
    "    valence_model.fit(dev_features_valence, dev_annotations[:,0])\n",
    "    valence_pred = valence_model.predict(test_features_valence)\n",
    "    print(mean_squared_error(test_annotations[:,0], valence_pred), pearsonr(test_annotations[:,0], valence_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, precision_score, recall_score, precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import f_regression, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, fit_grid_point\n",
    "from sklearn import svm\n",
    "from scipy.stats import pearsonr\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(dev_features_raw, test_features_raw, annotations, maxk, reg=True, scale=True):\n",
    "    dev_features = preprocessing.minmax_scale(dev_features_raw, feature_range=(0, 1), axis=0) if scale else dev_features_raw\n",
    "    test_features = preprocessing.minmax_scale(test_features_raw, feature_range=(0, 1), axis=0) if scale else test_features_raw\n",
    "    print(dev_features.shape, test_features.shape)\n",
    "    bestk_selection = SelectKBest(f_regression if reg else f_classif, k=maxk)\n",
    "    dev_features_selected = bestk_selection.fit_transform(dev_features, annotations)\n",
    "    test_features_selected = bestk_selection.transform(test_features)\n",
    "    print(dev_features_selected.shape, test_features_selected.shape)\n",
    "    return dev_features_selected, test_features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_features = np.load('../data/dev_uploaded_data/vgg_features_avg.npy')\n",
    "# dev_features = np.load('../data/dev_uploaded_data/features_avg.npy')\n",
    "dev_annotations = np.load('../data/dev_uploaded_data/anno_valence_arousal.npy')\n",
    "dev_annotations_fear = np.load('../data/dev_uploaded_data/anno_fear.npy')\n",
    "test_features = np.load('../data/test_uploaded_data/vgg_features_avg.npy')\n",
    "# test_features = np.load('../data/test_uploaded_data/features_avg.npy')\n",
    "test_annotations = np.load('../data/test_uploaded_data/anno_valence_arousal.npy')\n",
    "test_annotations_fear = np.load('../data/test_uploaded_data/anno_fear.npy')\n",
    "dev_features_valence, test_features_valence = select_features(dev_features, test_features, \n",
    "                                                              dev_annotations[:, 0], 100)\n",
    "dev_features_arousal, test_features_arousal = select_features(dev_features, test_features, \n",
    "                                                              dev_annotations[:, 1], 100)\n",
    "dev_features_fear, test_features_fear = select_features(dev_features, test_features, dev_annotations_fear, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_model = RandomForestRegressor(min_samples_leaf=100, n_estimators=50, criterion='mse')\n",
    "valence_model.fit(dev_features_valence, dev_annotations[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_pred = valence_model.predict(test_features_valence)\n",
    "print(mean_squared_error(test_annotations[:,0], valence_pred), pearsonr(test_annotations[:,0], valence_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_param(parameter, num_range, index):\n",
    "    grid_search = GridSearchCV(valence_model, param_grid = {parameter: num_range}, scoring='r2')\n",
    "    grid_search.fit(dev_features_valence, dev_annotations[:,0])\n",
    "    df = {}\n",
    "    for i, score in enumerate(grid_search.grid_scores_):\n",
    "        df[score[0][parameter]] = score[1]\n",
    "    df = pd.DataFrame.from_dict(df, orient='index')\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.sort_values(by='index')\n",
    "    plt.subplot(3,2,index)\n",
    "    plot = plt.plot(df['index'], df[0])\n",
    "    plt.title(parameter)\n",
    "    return plot, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning\n",
    "param_grid = {\"max_depth\": np.arange(1, 10, 1)}\n",
    "index = 1\n",
    "plt.figure(figsize=(16,12))\n",
    "for parameter, param_range in dict.items(param_grid):   \n",
    "    evaluate_param(parameter, param_range, index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_model = RandomForestRegressor(min_samples_leaf=25, min_samples_split=50, criterion='mse')\n",
    "arousal_model.fit(dev_features_arousal, dev_annotations[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_pred = arousal_model.predict(test_features_arousal)\n",
    "print(mean_squared_error(test_annotations[:,1], arousal_pred), pearsonr(test_annotations[:,1], arousal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification method for fear model\n",
    "fear_model = RandomForestClassifier(class_weight={0:250, 1:1})\n",
    "fear_model.fit(dev_features_fear, dev_annotations_fear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_pred = fear_model.predict(test_features_fear)\n",
    "print(accuracy_score(test_annotations_fear, fear_pred), \n",
    "          precision_score(test_annotations_fear, fear_pred), \n",
    "          recall_score(test_annotations_fear, fear_pred),\n",
    "     f1_score(test_annotations_fear, fear_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression method for fear model\n",
    "fear_model = RandomForestRegressor(n_estimators=10, criterion='mse', min_samples_leaf=20)\n",
    "fear_model.fit(dev_features_fear, dev_annotations_fear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning\n",
    "for val in range(1, 50, 1):\n",
    "    fear_model = RandomForestRegressor(n_estimators=10, criterion='mse', min_samples_leaf=val)\n",
    "    fear_model.fit(dev_features_fear, dev_annotations_fear)\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for i in range(1, 45, 1):\n",
    "        fear_pred = fear_model.predict(test_features_fear)\n",
    "        fear_pred = fear_pred > i / 100.\n",
    "        f1 = f1_score(test_annotations_fear, fear_pred)\n",
    "        if(f1 > best_f1):\n",
    "            best_f1 = f1\n",
    "            best_threshold = i / 100.\n",
    "    print(\"val={}, best f1={}, best threshold={}\".format(val, best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning\n",
    "for i in range(1, 45, 1):\n",
    "    fear_pred = fear_model.predict(test_features_fear)\n",
    "    fear_pred = fear_pred > i / 100.\n",
    "    print('threshold = {}'.format({i / 100.}))\n",
    "    print(accuracy_score(test_annotations_fear, fear_pred), \n",
    "          precision_score(test_annotations_fear, fear_pred), \n",
    "          recall_score(test_annotations_fear, fear_pred),\n",
    "         f1_score(test_annotations_fear, fear_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
